{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7d17522a-4ee2-4c8a-9d9c-83738ea9fe8e",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4e456b6-70dd-47ad-920b-dd85da988727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\roari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\roari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\roari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import ast\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af44597-086e-42de-8229-67110639ddaf",
   "metadata": {},
   "source": [
    "Libraries Used:\n",
    "pandas: For data manipulation and analysis, particularly to handle and clean the dataset.\n",
    "numpy: For numerical operations, used here for array manipulations.\n",
    "sklearn.metrics.pairwise.cosine_similarity: From scikit-learn, computes the cosine similarity between vectors.\n",
    "torch and transformers: From Hugging Face's Transformers library, used for natural language processing tasks with pre-trained models."
   ]
  },
  {
   "cell_type": "raw",
   "id": "489aefa1-2204-4382-81c9-755ce9697f0a",
   "metadata": {},
   "source": [
    "Loading the Dataset and Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06ba77bf-7950-4ff8-9868-9dd6784f2cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (31597, 9)\n",
      "Size: 284373\n",
      "Columns: Index(['job_title', 'company_name', 'location', 'hiring_status', 'date',\n",
      "       'seniority_level', 'job_function', 'employment_type', 'industry'],\n",
      "      dtype='object')\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31597 entries, 0 to 31596\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   job_title        31571 non-null  object        \n",
      " 1   company_name     30657 non-null  object        \n",
      " 2   location         31588 non-null  object        \n",
      " 3   hiring_status    31597 non-null  object        \n",
      " 4   date             31597 non-null  datetime64[ns]\n",
      " 5   seniority_level  30289 non-null  object        \n",
      " 6   job_function     30007 non-null  object        \n",
      " 7   employment_type  30006 non-null  object        \n",
      " 8   industry         29586 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(8)\n",
      "memory usage: 2.2+ MB\n",
      "None\n",
      "Count of null values:\n",
      " job_title            26\n",
      "company_name        940\n",
      "location              9\n",
      "hiring_status         0\n",
      "date                  0\n",
      "seniority_level    1308\n",
      "job_function       1590\n",
      "employment_type    1591\n",
      "industry           2011\n",
      "dtype: int64\n",
      "Count after dropping null values:\n",
      " job_title          0\n",
      "company_name       0\n",
      "location           0\n",
      "hiring_status      0\n",
      "date               0\n",
      "seniority_level    0\n",
      "job_function       0\n",
      "employment_type    0\n",
      "industry           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file\n",
    "datafile_path = r\"C:\\Users\\roari\\Downloads\\linkedin_job.xlsx\"\n",
    "df = pd.read_excel(datafile_path)\n",
    "\n",
    "# Initial data inspection\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Size:\", df.size)\n",
    "print(\"Columns:\", df.columns)\n",
    "print(\"Info:\")\n",
    "print(df.info())\n",
    "print(\"Count of null values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Drop rows with null values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Count after dropping nulls\n",
    "print(\"Count after dropping null values:\\n\", df_cleaned.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2c24477-04b4-4201-b089-ffab7518c036",
   "metadata": {},
   "source": [
    "Processing text, Generating embedding, Extracting relevant sentence, Embedding Generation for Job Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0197164a-f0e0-48c5-a296-b850da9f1faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = str(text).lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def generate_embedding(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "def extract_relevant_sentences(summary, query_embedding, tokenizer, model, k=2):\n",
    "    sentences = summary.split(\".\")\n",
    "    sentence_embeddings = [generate_embedding(sentence, tokenizer, model) for sentence in sentences]\n",
    "    similarities = [cosine_similarity(query_embedding.reshape(1, -1), sentence_embedding.reshape(1, -1))[0, 0] for sentence_embedding in sentence_embeddings]\n",
    "    top_k_indices = np.argsort(similarities)[-k:]\n",
    "    return [sentences[index] for index in top_k_indices]\n",
    "\n",
    "def search_authors_and_relevant_parts(df, query, tokenizer, model, n=3, k=2):\n",
    "    query_embedding = generate_embedding(query, tokenizer, model)\n",
    "    df[\"similarity\"] = df[\"embedding\"].apply(lambda x: cosine_similarity(x.reshape(1, -1), query_embedding.reshape(1, -1))[0, 0])\n",
    "    top_n_results = df.sort_values(\"similarity\", ascending=False).head(n)\n",
    "\n",
    "    for _, row in top_n_results.iterrows():\n",
    "        relevant_parts = extract_relevant_sentences(row[\"summary\"], query_embedding, tokenizer, model, k)\n",
    "        print(f\"Job Title: {row['job_title']} (similarity: {row['similarity']:.4f})\")\n",
    "        print(f\"Relevant parts: {'.'.join(relevant_parts)}...\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf6a4219-23ec-4c5e-a2e1-fb6610b38f52",
   "metadata": {},
   "source": [
    "Loading pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8405ee31-ed63-496f-965f-8657ef06ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30a10793-1051-447f-bb94-e501caa17b03",
   "metadata": {},
   "source": [
    "Saving embeddings to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11fcd993-61a7-4376-80b2-787fdd2b5391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|█████████████████████████████████████████████████████| 27972/27972 [17:26<00:00, 26.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a summary column with all relevant metadata concatenated\n",
    "df_cleaned.loc[:, 'summary'] = df_cleaned.apply(\n",
    "    lambda x: f\"{x['job_title']} {x['company_name']} {x['location']} {x['hiring_status']} {x['date']} {x['seniority_level']} {x['job_function']} {x['employment_type']} {x['industry']}\", axis=1)\n",
    "\n",
    "# Preprocess the summary text\n",
    "df_cleaned.loc[:, \"preprocessed_summary\"] = df_cleaned[\"summary\"].apply(preprocess_text)\n",
    "\n",
    "# Generate embeddings and save them, avoiding comma errors\n",
    "embeddings = []\n",
    "for summary in tqdm(df_cleaned[\"preprocessed_summary\"], desc=\"Generating embeddings\"):\n",
    "    embedding = generate_embedding(summary, tokenizer, model)\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "# Convert embeddings to a format that can be saved without comma errors\n",
    "df_cleaned.loc[:, \"embedding\"] = embeddings\n",
    "df_cleaned.loc[:, \"embedding\"] = df_cleaned[\"embedding\"].apply(lambda x: ', '.join(map(str, x[0])))\n",
    "\n",
    "# Save the DataFrame with embeddings to a CSV file\n",
    "df_cleaned.to_csv(\"summaries_with_embeddings.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4048d06f-1f60-4bd0-9713-3e24cc54d317",
   "metadata": {},
   "source": [
    "Loading that embedded CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0af92874-101e-48c1-8605-7329ca3aa44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "df_with_embeddings = pd.read_csv(\"summaries_with_embeddings.csv\")\n",
    "\n",
    "# Convert the embeddings from strings back to numpy arrays\n",
    "df_with_embeddings[\"embedding\"] = df_with_embeddings[\"embedding\"].apply(\n",
    "    lambda x: np.array([float(num) for num in x.split(', ')])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70a20304-23c3-44d7-b0a4-833d6db9f789",
   "metadata": {},
   "source": [
    "Semantic Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a46926d6-d31b-4dbe-8320-c2aa3e258366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def search(query, df, tokenizer, model, top_n=5):\n",
    "    # Preprocess the query\n",
    "    preprocessed_query = preprocess_text(query)\n",
    "    \n",
    "    # Generate the embedding for the query\n",
    "    query_embedding = generate_embedding(preprocessed_query, tokenizer, model)[0]\n",
    "    \n",
    "    # Compute cosine similarity between the query embedding and the job embeddings\n",
    "    similarities = cosine_similarity([query_embedding], list(df[\"embedding\"]))\n",
    "    \n",
    "    # Add similarity scores to the DataFrame\n",
    "    df[\"similarity_score\"] = similarities[0]\n",
    "    \n",
    "    # Get the top N most similar results\n",
    "    top_n_indices = np.argsort(similarities[0])[-top_n:][::-1]\n",
    "    top_n_results = df.iloc[top_n_indices]\n",
    "    \n",
    "    return top_n_results\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "779a0669-d1e6-4b92-a136-f9d36b732a90",
   "metadata": {},
   "source": [
    "cosine_similarity from scikit-learn: To Computes cosine similarity between vectors."
   ]
  },
  {
   "cell_type": "raw",
   "id": "688ba6ba-5928-4852-a22f-8eb3007b6414",
   "metadata": {},
   "source": [
    "Taking useer input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a674652c-c0c9-44e5-83be-77468e545bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or 'exit' to quit):  financial job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top results for 'financial job':\n",
      "Job Title: Data Scientist\n",
      "Company: Finder\n",
      "Location: Sydney, New South Wales, Australia\n",
      "Similarity Score: 0.5708\n",
      "-------------------------\n",
      "Job Title: Data Scientist\n",
      "Company: Finder\n",
      "Location: Sydney, New South Wales, Australia\n",
      "Similarity Score: 0.5708\n",
      "-------------------------\n",
      "Job Title: Data Scientist\n",
      "Company: Finder\n",
      "Location: Sydney, New South Wales, Australia\n",
      "Similarity Score: 0.5708\n",
      "-------------------------\n",
      "Job Title: Data Scientist\n",
      "Company: Finder\n",
      "Location: Sydney, New South Wales, Australia\n",
      "Similarity Score: 0.5708\n",
      "-------------------------\n",
      "Job Title: Data Scientist\n",
      "Company: Finder\n",
      "Location: Sydney, New South Wales, Australia\n",
      "Similarity Score: 0.5708\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or 'exit' to quit):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Ask the user for input query\n",
    "    query = input(\"Enter your query (or 'exit' to quit): \")\n",
    "    \n",
    "    # Check if the user wants to exit\n",
    "    if query.lower() == 'exit':\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "    \n",
    "    # Perform semantic search using the search function\n",
    "    results = search(query, df_with_embeddings, tokenizer, model)\n",
    "    \n",
    "    # Display the top results\n",
    "    print(f\"\\nTop results for '{query}':\")\n",
    "    for index, row in results.iterrows():\n",
    "        print(f\"Job Title: {row['job_title']}\")\n",
    "        print(f\"Company: {row['company_name']}\")\n",
    "        print(f\"Location: {row['location']}\")\n",
    "        print(f\"Similarity Score: {row['similarity_score']:.4f}\")\n",
    "        print(\"-------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22970d0e-815f-48c5-9183-79729d303026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or 'exit' to quit):  Data engineering jobs in Australia\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top results for 'Data engineering jobs in Australia':\n",
      "Job Title: Data Scientist (remote, freelance)\n",
      "Company: Hire Digital\n",
      "Location: Melbourne, Victoria, Australia\n",
      "Similarity Score: 0.7292\n",
      "-------------------------\n",
      "Job Title: Data Scientist (Remote)\n",
      "Company: Hire Digital\n",
      "Location: Melbourne, Victoria, Australia\n",
      "Similarity Score: 0.7291\n",
      "-------------------------\n",
      "Job Title: Data Scientist (Python, Django)\n",
      "Company: Talent\n",
      "Location: Melbourne, Victoria, Australia\n",
      "Similarity Score: 0.7243\n",
      "-------------------------\n",
      "Job Title: Data Scientist (Python, Django)\n",
      "Company: Talent\n",
      "Location: Melbourne, Victoria, Australia\n",
      "Similarity Score: 0.7243\n",
      "-------------------------\n",
      "Job Title: Data Scientist (Python, Django)\n",
      "Company: Talent\n",
      "Location: Melbourne, Victoria, Australia\n",
      "Similarity Score: 0.7243\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or 'exit' to quit):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Ask the user for input query\n",
    "    query = input(\"Enter your query (or 'exit' to quit): \")\n",
    "    \n",
    "    # Check if the user wants to exit\n",
    "    if query.lower() == 'exit':\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "    \n",
    "    # Perform semantic search using the search function\n",
    "    results = search(query, df_with_embeddings, tokenizer, model)\n",
    "    \n",
    "    # Display the top results\n",
    "    print(f\"\\nTop results for '{query}':\")\n",
    "    for index, row in results.iterrows():\n",
    "        print(f\"Job Title: {row['job_title']}\")\n",
    "        print(f\"Company: {row['company_name']}\")\n",
    "        print(f\"Location: {row['location']}\")\n",
    "        print(f\"Similarity Score: {row['similarity_score']:.4f}\")\n",
    "        print(\"-------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "979d4f58-770e-4182-866a-36a9896013a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, df, tokenizer, model, top_n=5):\n",
    "    # Preprocess the query\n",
    "    preprocessed_query = preprocess_text(query)\n",
    "    \n",
    "    # Generate the embedding for the query\n",
    "    query_embedding = generate_embedding(preprocessed_query, tokenizer, model)[0]\n",
    "    \n",
    "    # Compute cosine similarity between the query embedding and the job embeddings\n",
    "    similarities = cosine_similarity([query_embedding], list(df[\"embedding\"]))\n",
    "    \n",
    "    # Add similarity scores to the DataFrame\n",
    "    df[\"similarity_score\"] = similarities[0]\n",
    "    \n",
    "    # Get the top N most similar results\n",
    "    top_n_indices = np.argsort(similarities[0])[-top_n:][::-1]\n",
    "    top_n_results = df.iloc[top_n_indices]\n",
    "    \n",
    "    return top_n_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "648ca902-395f-45be-9ad8-190ece2c23ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or 'exit' to quit):  data Analyst job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results for 'data analyst job':\n",
      "Job Title: Decision Science Modelling - Senior Analyst\n",
      "Company: Datatech Analytics\n",
      "Location: London Area, United Kingdom\n",
      "Similarity Score: 0.6210\n",
      "-------------------------\n",
      "Job Title: Trading Analytics Manager (Data Scientist)\n",
      "Company: Swish Analytics\n",
      "Location: San Francisco, CA\n",
      "Similarity Score: 0.6200\n",
      "-------------------------\n",
      "Job Title: Trading Analytics Manager (Data Scientist)\n",
      "Company: Swish Analytics\n",
      "Location: San Francisco, CA\n",
      "Similarity Score: 0.6200\n",
      "-------------------------\n",
      "Job Title: Senior Data Scientist\n",
      "Company: Harnham\n",
      "Location: London, England, United Kingdom\n",
      "Similarity Score: 0.6073\n",
      "-------------------------\n",
      "Job Title: Senior Data Scientist\n",
      "Company: Harnham\n",
      "Location: London, England, United Kingdom\n",
      "Similarity Score: 0.6031\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or 'exit' to quit):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Ask the user for input query\n",
    "    query = input(\"Enter your query (or 'exit' to quit): \")\n",
    "    \n",
    "    # Check if the user wants to exit\n",
    "    if query.lower() == 'exit':\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "    \n",
    "    # Perform semantic search using the search function\n",
    "    results = search(query, df_with_embeddings, tokenizer, model)\n",
    "    \n",
    "    # Display the top results\n",
    "    print(f\"\\nTop results for '{query}':\")\n",
    "    for index, row in results.iterrows():\n",
    "        print(f\"Job Title: {row['job_title']}\")\n",
    "        print(f\"Company: {row['company_name']}\")\n",
    "        print(f\"Location: {row['location']}\")\n",
    "        print(f\"Similarity Score: {row['similarity_score']:.4f}\")\n",
    "        print(\"-------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "844f79c4-bed2-4aca-b53a-3ce7d81a50ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or 'exit' to quit):  hey i want to study in USA please suggest me some Cloud related jobs in Amazon \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top results for 'hey i want to study in USA please suggest me some Cloud related jobs in Amazon ':\n",
      "Job Title: \n",
      "            \n",
      "        Civil Engineer\n",
      "      \n",
      "          \n",
      "Company: \n",
      "            Amazon Web Services (AWS)\n",
      "          \n",
      "Location: \n",
      "            Sydney, New South Wales, Australia\n",
      "          \n",
      "Similarity Score: 0.6098\n",
      "-------------------------\n",
      "Job Title: Executive Assistant, Corporate Development\n",
      "Company: Amazon\n",
      "Location: San Francisco, CA\n",
      "Similarity Score: 0.5857\n",
      "-------------------------\n",
      "Job Title: \n",
      "            \n",
      "        Civil Engineer\n",
      "      \n",
      "          \n",
      "Company: \n",
      "            Amazon Web Services (AWS)\n",
      "          \n",
      "Location: \n",
      "            Sydney, New South Wales, Australia\n",
      "          \n",
      "Similarity Score: 0.5756\n",
      "-------------------------\n",
      "Job Title: \n",
      "            \n",
      "        AWS Cloud Architect\n",
      "      \n",
      "          \n",
      "Company: \n",
      "            Digital Janet\n",
      "          \n",
      "Location: \n",
      "            United States\n",
      "          \n",
      "Similarity Score: 0.5719\n",
      "-------------------------\n",
      "Job Title: \n",
      "            \n",
      "        L3 Cloud Engineer - Applied Cloud Computing\n",
      "      \n",
      "          \n",
      "Company: \n",
      "            Applied Cloud Computing\n",
      "          \n",
      "Location: \n",
      "            Mumbai, Maharashtra, India\n",
      "          \n",
      "Similarity Score: 0.5649\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or 'exit' to quit):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Ask the user for input query\n",
    "    query = input(\"Enter your query (or 'exit' to quit): \")\n",
    "    \n",
    "    # Check if the user wants to exit\n",
    "    if query.lower() == 'exit':\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "    \n",
    "    # Perform semantic search using the search function\n",
    "    results = search(query, df_with_embeddings, tokenizer, model)\n",
    "    \n",
    "    # Display the top results\n",
    "    print(f\"\\nTop results for '{query}':\")\n",
    "    for index, row in results.iterrows():\n",
    "        print(f\"Job Title: {row['job_title']}\")\n",
    "        print(f\"Company: {row['company_name']}\")\n",
    "        print(f\"Location: {row['location']}\")\n",
    "        print(f\"Similarity Score: {row['similarity_score']:.4f}\")\n",
    "        print(\"-------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ff0fbc4-8c62-4827-9617-683327208650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or 'exit' to quit):  List all marketing jobs. Please take USA Jobs on top\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top results for 'List all marketing jobs. Please take USA Jobs on top':\n",
      "Job Title: \n",
      "            \n",
      "        Marketing Manager, Marketplaces\n",
      "      \n",
      "          \n",
      "Company: \n",
      "            Sonos, Inc.\n",
      "          \n",
      "Location: \n",
      "            United States\n",
      "          \n",
      "Similarity Score: 0.5633\n",
      "-------------------------\n",
      "Job Title: \n",
      "            \n",
      "        Marketing Manager\n",
      "      \n",
      "          \n",
      "Company: \n",
      "            LHH\n",
      "          \n",
      "Location: \n",
      "            Washington DC-Baltimore Area\n",
      "          \n",
      "Similarity Score: 0.5512\n",
      "-------------------------\n",
      "Job Title: \n",
      "            \n",
      "        Marketing Manager\n",
      "      \n",
      "          \n",
      "Company: \n",
      "            GRADIENT\n",
      "          \n",
      "Location: \n",
      "            United States\n",
      "          \n",
      "Similarity Score: 0.5466\n",
      "-------------------------\n",
      "Job Title: \n",
      "            \n",
      "        Vice President Marketing\n",
      "      \n",
      "          \n",
      "Company: \n",
      "            Confidential\n",
      "          \n",
      "Location: \n",
      "            United States\n",
      "          \n",
      "Similarity Score: 0.5370\n",
      "-------------------------\n",
      "Job Title: \n",
      "            \n",
      "        Marketing Manager, Marketplaces\n",
      "      \n",
      "          \n",
      "Company: \n",
      "            Sonos, Inc.\n",
      "          \n",
      "Location: \n",
      "            United States\n",
      "          \n",
      "Similarity Score: 0.5269\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or 'exit' to quit):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Ask the user for input query\n",
    "    query = input(\"Enter your query (or 'exit' to quit): \")\n",
    "    \n",
    "    # Check if the user wants to exit\n",
    "    if query.lower() == 'exit':\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "    \n",
    "    # Perform semantic search using the search function\n",
    "    results = search(query, df_with_embeddings, tokenizer, model)\n",
    "    \n",
    "    # Display the top results\n",
    "    print(f\"\\nTop results for '{query}':\")\n",
    "    for index, row in results.iterrows():\n",
    "        print(f\"Job Title: {row['job_title']}\")\n",
    "        print(f\"Company: {row['company_name']}\")\n",
    "        print(f\"Location: {row['location']}\")\n",
    "        print(f\"Similarity Score: {row['similarity_score']:.4f}\")\n",
    "        print(\"-------------------------\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6bce7925-8728-49aa-864b-ffd397921903",
   "metadata": {},
   "source": [
    "End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
